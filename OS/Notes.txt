Operating System - Part I

1. Turn-Around time = Burst-time + I/O + waiting time
2. CPU time/total CPU time
3. Long term Scheduler (process moved from HD to RAM) and short term scheduler (RAM to CPU) & Medium term Scheduler (RAM to HD)
4. process and program
5. Life Cycle of Process (7 states)	
    - New State 	
    - Ready State	
    - Running State	
    - Waiting Sate or Blocked State or I/O State	
    - Termination State	
    - Suspend Ready
    - Suspend Wait or Suspend Blocked
6. Process Attribute	
    - process ID	
    - Program counter (register)	
    - Process State	
    - General purpose Register	
    - Priority	
    - List of open files	
    - List of open devices	
    - Protection
7. Scheduling, Preemption and Timestamp
8. Degree of Multiprogramming
9. Types of OS 	
    - Batch OS	
    - Multiprogramming OS (1 CPU) (concurrent processing)	
    - Multiprocessing OS (more than 1 CPU) (parallel processing)
10. PCB (Process Control Block)	
    - Stack	
    - Heap	
    - Static and Global Variables	
    - program
11. Passive (program) and Active Entity (process)
12. Types of Scheduler
13. Context of a process (PCB + process attributes)
14. Context Switching.
15. Swapping - swap-in & swap-out
16. Point in time vs Duration in time (Burst time + Turn around time + Waiting time + Response Time)
17. Various times related to a process 	
    - Arrival time	
    - Burst time (execution time)	
    - Completion time	
    - Turn around time (completion time - arrival time) (Burst time + Waiting time + I/O time) (total time inside the RAM)	
    - Waiting time	
    - Response time	
    - I/O time
18. CPU Scheduling Algo	
    - Preemptive 	
    - Non PreemptiveNote 
    - CPU scheduling algo are applied only to process which are in the Ready State.
19. Shortest Job First Scheduling Algo (SJF)	
    - Among the arrived process, process with the least burst time will be given preference.	
    - Non Preemptive Algo	
    - Priority based Algo
20. Gantt Chart
21. Schedule length = completion time of last process - arrival time of first process
22. Throughput - number of process executed / schedule length
23. SRTF (Shortest Remaining Time First Scheduling Algorithm) 	- Preemptive version of SJF.
24. Response Time (waiting time of the process until it get CPU for the 1st time)Note - In any non-preemptive scheduling algorithm Response time = waiting time, But this need not be true for preemptive scheduling algo
25. First Come First Serve (FCFS)	
    - The process with the least arrival time	
    - non-preemptive scheduling algo	
    - It is not a priority based scheduling
26. Starvation problemNote 
    - Any priority based algo will suffer from Starvation
27. Convoy Effect (A smaller process (process with very small execution time) waiting for one big process to get off (release))
28. Throughput - No. of process executed in a unit time
29. LJF (Longest Job First Scheduling Algorithm)	
    - non preemptive	
    - priority based algorithm	
    - Starvation problem exists	
    - Convoy effect problem exists	
    - Throughput is very less	
    - Practically very difficult to implement
30. LRTF (Longest Remaining Time First Scheduling Algorithm)	
    - preemptive	
    - starvation problem exists.	
    - convoy effect problem exists.	
    - throughput is very less	
    - practically difficult to implement
31. Time Quantum (maximum allowable time a process can run without getting preempted)
32. Round Robin Scheduling Algorithm (Time Quantum + FCFS)	
    - it not priority based algo.	
    - it works on the basis of a particular time quantum.		
    - Uses Queue data structure	- very popular and used in most of the OS's today
33. RR observations	- Has time quantum increases the context switching may decrease	
    - Has time quantum increases the response time may increase
34. RR Advantages and Limitations	 
    Advantages	
        - No starvation problem	
        - No convoy-effect problem	
        - Practically Implementable	
        - Response time is also good	
    Limitations	
        - Throughput is good but not as good as SJF, SRTF
35. Priority based Scheduling Algo	
    - Mode: Both preemptive and non-preemptive
36. SRTF with process requiring CPU and I/O time
37. Advantages and Disadvantages of SJF	
    Advantages		
        - Throughput is High	
    Disadvantages	
        - Larger process may wait indefinitely or starve
38. Highest Response Ratio Next Scheduling Algorithm (HRRN)	
    - Mode: non-premptive	
    - Response ratio = (w+b)/b		
    - w: waiting time of a process so far		
    - b: burst time39. Process State Diagram
40. Dispatcher
41. Basics of Binary Number System

#Memory Allocation Techniques
42. Basics of Memory Allocation
43. Address space (collection of addresses)	
    - physical address space (instruction address in the RAM)	
    - logical address space (address of a process)44. Various methods used to read the process to main memory	
    - Contigious Allocation (All the address of the logical address space is placed in a congitious in Phyisical address)		
    - Fixed partitioning (Also called as static partitioning)		
    - Variable partitioning (Also called as dynamic partitioning)	
    - Non-Contigious Allocation45. Disadvantages of Fixed partitioning	
    - Internal Fragmentation problem exists	
    - Process size is limited by the size of the largest partition	
    - Degree of Multiprogramming is limited by the number of partitions
46. Rules of Fixed partition	
    - a partition can hold only one process data	
    - a process can be placed in only one partition and it cannot span across 2 or more partitions
Note: No External Fragmentation problem in Fixed partitioning
47. Variable Paritioning (Dynamic partitioning)	
    - No Internal Fragmentation problem	
    - Degree of Multiprogramming is not limited	
    - Size of a process is not limited by size of largest partition rather it is limited by the size of RAM
Note: Variable partitioning suffers from the problem of External Fragmentation (because of congitious allocation)
48. Memory Allocation Algorithm	
    - First fit	
    - Next fit	
    - Best fit	
    - Worst fit
49. Binary Addressing Revisited	
    - Byte Addressable System
50. Solution for External Fragmentation	
    - Compaction	
    - Paging (Non Contigious Allocation)


#OS PartII
1. Paging (Non Contigious Allocation)	
    - Suffers from internal Fragmentation (but very less only at 2 places that is the last page of the process and page table of a process)
2. How CPU excecutes a process in Contigious Allocation
3. Basics of Paging	
    - Page Size	
    - Frame Size (Fixed size blocks in RAM)
Note: Frame Size and Page Size are always equal	
    - Pages (Blocks of processes)	
    - Frames (Blocks of RAM)	
    - Page Table	
    - Byte Addressable System (Every byte will have a unique address)
Note: External Fragmentation is not possible in the Paging
**3.Paging (revise)	    
    - No. of Frames = PAS(Process Address Space) or RAM size / Frame size	
    - No. of Pages = LAS(Logical Address Space) or Process size / Page size
Note: Frage size and Page size are always equal 
Note: Page table is called as Memory Management Unit	
    - Page Table Size = No. of entries in the Pagetable * size of a single entry of PT
4. Relation between LA, LAS and PA, PAS	
5. Multilevel paging need (when the size of a page table is greater than the frame size)
    - No. of entries in the page table = Page Size / size of Page Table Entry
6. Multilevel Paging Problems

**Important point to note    
    - We always try to maintain pages of our process in the RAM. Why ? 
    - Because if the byte which CPU is asking for is present in the RAM, it will take very less time for the CPU to fetch and execute. 
    - But if the byte (byte will present in a page) which CPU is asking for, is not present in the RAM, 
        we might have to move the page from hard disk to RAM and then CPU will fetch the byte from the RAM, 
        which will take more time as accessing Hard disk is very very time consuming. 
    - So if we can have the page which CPU will refer next in the RAM, 
        then it will take very less time for the fetching by CPU. 
    - But this is not possible always because of 2 reasons.
        1) Which page will CPU refer next is unknown before, because we cannot know the future. 
            Which means we dont know which page will CPU refer next as it is future.
        2) RAM size is small compared to hard disk size. So we cannot have all the bytes of hard disk in the RAM.
    - So what we do is, we predict (guess) which page will CPU refer next and place that page in the RAM. 
    NOTE :This is just a guess which can also be wrong. (Just like predicting which team will win in tomorrow's game).
    - Now if our guess is correct, page accessing time is less for the CPU for that byte.
    - But if guess is wrong, then fetching that byte will take more time as we need to move the data from hard disk to RAM and then CPU will read from the RAM.

#Page Table Entry
7. Frame number field and Referenced bit
    - Important Point: For every page of our proccess we maintain a pagatable entry. so, every Pagetable entry will describe its corresponding pages properties
    - Fields in the Pagetable entry
        - Page Frame No.
            - This field holds the physical frame number where the page is stored in memory. 
        - Referenced bit
            - Also known as the Accessed bit — it indicates whether the page has been accessed/read recently.
            - The OS can use this bit to implement page replacement algorithms (like LRU — Least Recently Used).
        - Modified bit or Dirty bit
            - This bit shows whether the page has been modified (written to) since it was loaded into memory.
            - If a page is dirty, it must be written back to disk before it can be swapped out, ensuring data integrity.
            - If not dirty, the page can be discarded without writing back to disk.
        - Protection bit
            - Controls access permissions for the page — it dictates what type of access is allowed:
                - Read-only
                - Read-Write
                - Execute
            - This prevents unauthorized processes from altering or executing certain pages.
        - Present/Absent bit
            - Also called the valid bit, this indicates whether the page is currently in physical memory (RAM).
            - 1 (Present/Valid): The page is in memory, and its PFN is valid.
            - 0 (Absent/Invalid): The page is not in memory — it may be on disk (swap space) or unallocated.
            - If absent, a page fault occurs when the process tries to access the page.
    - Page Replacement (replacing lower priority page from the RAM and replace with higher priority page from the hard disk) (0  or 1)
8. Present/ Absent bit and Dirty bit
9. Protection bits
10. Advantage of Dirty bit field in Page Table entry
    - Dirty bits for a page in pagetable helps to aviod unnecessary writes to harddisk
11. Page Table Entry Problems.

#Virtual Memory
12. Locality of Reference and Virtual Memory
    - Principle of Locality: Says that at anytime a process will require only few pages and these set of pages will gradually change over time.
    - Virtual Memory: We maintain only few pages of our process in the RAM. Such a memory is called as Virtual Memory. And the set of addresses (part of process)
        which are inside the RAM is also called as Virtual Address Space.
13. Advantages of Virtual Memory
    - Degree of Multiprogramming is higher (then not using them)
    - We will be able to excecute even process whose size is larger than the size of RAM. (This is not possible if we dont use virtual memory)

#Average Memory Access Time (AMAT)
14. Page Hit and Page fault
    - Page Hit: If the page containing the byte or word, which CPU wants is present inside the RAM is called as Page Hit
    - Page Fault/Miss: If the page containing the byte or word, which CPU wants is not present inside the RAM is called as Page Fault/Miss.
15. Average/Effective Memory Access Time
16. Another way of looking at AMAT
17. Relation between Number of levels of Paging and Number of RAM Access

#Translation Lookaside Buffer (TLB)
18. Need for TLB
19. TLB Explination
    - TLB is a small cache of page table entries. It is used to speed up the process of page table lookups.
20. Computing TLB Hit Ratio
21. Computing TLB Access Time
22. Computing RAM Access Time
23. Problems on TLB

#Frame Allocation 
24. Need for Frame Allocation for a process
    - Thrashing- A situation where the process is constantly being swapped in and out of memory, resulting in poor performance.
25. Frame Allocation methods
26. Difference between Static and Dynamic
    - Static Allocation
        - Equal Allocation
        - Allocation based on process size
    - Dynamic Allocation
        - Starvation problem may occur
27. Dynamic Frame Allocation
28. Starvation Problem Revisited

#Page Replacement algorithms
29. Local vs Global Page Replacement
    - Local Page Replacement: The page replacement is done on the basis of the pages of a process.
    - Global Page Replacement: The page replacement is done on the basis of the pages of all the processes.
Note: Local Page Replacement Algorithm is mostly used
30. Demand Paging- We will not load any page of a process until CPU requests for a byte in that page
31. LRU (Least Recently Used) Page Replacement Algorithm
32. Page Reference String- A sequence of page numbers that a process accesses in a particular order
33. FIFO (First In First Out) Page Replacement Algorithm
34. Optimal Page Replacement Algorithm (Best Algo which gives the least number of page faults)
    - Disadvantage: Its implementation is not practically possible because we can't know the future page references.
35. MRU (Most Recently Used) Page Replacement Algorithm
36. LIFO (Last In First Out) Page Replacement Algorithm
37. Page Fault Rate- The number of page faults / Total number of references
Note - If we use Demand Paging and if number of distinct pages in page reference string n then no: of pagefaults >= n
     - If we use Demand Paging and if all the pages in page reference string is distinct, then number of pagefaults = m, 
        where m is the number of pages in page reference string
38. Advanced Problems on Page Replacement Algorithm